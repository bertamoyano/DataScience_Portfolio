```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
```

# Anàlisi discriminant lineal

L'anàlisi discriminant lineal, o LDA, és un mètode de classificació dins de l'aprenentatge supervisat que permet classificar una variable categòrica entre els seus diferents nivells. Per classificar entre diferents classes s'estimen una o diverses funcions discriminants, que representen hiperplans i separen l'espai d'observacions en diferents regions.

Com que el LDA està basat en mètodes factorials, es prenen només les columnes numèriques com a variables predictives. 

La variable que es vol classificar és la variable Target, la qual té 4 modalitats: Dropout, Enrolled, Graduate i Unknown. S'eliminen les observacions de la modalitat Unknown, ja que en realitat són *missing values* i no té sentit que formin una categoria específica en la qual classificar observacions.

```{r}
data = get(load('data_post_pca.RData'))

# es pren la columna Target com a variable objectiu que es vol predir
data$target <- as.factor(data$target)

# s'eliminen les files que són unknown (no té gaire sentit mantenir-les des d'un punt de vista de classificació)
data_clas = subset(data, target != 'Unknown')
data_clas$target <- droplevels(data_clas$target)

# es recodifica la variable objectiu
levels(data_clas$target) = c(1:3)

# es necessiten X's numèriques
numeric = which(sapply(data_clas, is.numeric))
data_numeric = data_clas[, numeric]
# data_numeric = scale(data_numeric) --> estandarditzar totes les columnes no millora els resultats de la classificació
```

Com que hi ha 3 modalitats per a la variable Target, es busquen dues funcions discriminants per garantir que es pugui arribar a discriminar i separar entre les tres classes. La següent taula mostra els coeficients de les funcions discriminants:

```{r}
library(knitr)
library(MASS)

lda = lda(data_numeric, grouping = data_clas$target)

kable(lda$scaling[,1:2], format = "simple")
```

Com que s'han calculat dues funcions discriminants, apareixen dues columnes noves que s'afegeixen a la base de dades que conté les columnes numèriques de la base original. 

```{r}
# es col·loquen els valors dels coeficients en dues columnes noves
lda.values = predict(lda, data_numeric)
data_clas$lda1 = lda.values$x[,1]
data_clas$lda2 = lda.values$x[,2]
names(data_clas$lda1) = 'LDA1'
names(data_clas$lda2) = 'LDA2'
```

```{r funció descriptiva de cada grup, include=FALSE}
calcWithinGroupsVariance <- function(variable,groupvariable)
{
  # find out how many values the group variable can take
  groupvariable2 <- as.factor(groupvariable[[1]])
  levels <- levels(groupvariable2)
  numlevels <- length(levels)
  # get the mean and standard deviation for each group:
  numtotal <- 0
  denomtotal <- 0
  for (i in 1:numlevels)
  {
    leveli <- levels[i]
    levelidata <- variable[groupvariable==leveli,]
    levelilength <- length(levelidata)
    # get the standard deviation for group i:
    sdi <- sd(levelidata)
    numi <- (levelilength - 1)*(sdi * sdi)
    denomi <- levelilength
    numtotal <- numtotal + numi
    denomtotal <- denomtotal + denomi
  }
  # calculate the within-groups variance
  Vw <- numtotal / (denomtotal - numlevels)
  return(Vw)
}
```

```{r funció estandaritzadora dels grups, include=FALSE}
groupStandardise <- function(variables, groupvariable)
{
  # find out how many variables we have
  variables <- as.data.frame(variables)
  numvariables <- length(variables)
  # find the variable names
  variablenames <- colnames(variables)
  # calculate the group-standardised version of each variable
  for (i in 1:numvariables)
  {
    variablei <- variables[i]
    variablei_name <- variablenames[i]
    variablei_Vw <- calcWithinGroupsVariance(variablei, groupvariable)
    variablei_mean <- mean(as.matrix(variablei))  
    variablei_new <- (variablei - variablei_mean)/(sqrt(variablei_Vw))
    data_length <- nrow(variablei)
    if (i == 1) { variables_new <- data.frame(row.names=seq(1,data_length)) }
    variables_new[`variablei_name`] <- variablei_new
  }
  return(variables_new)
}
```

```{r funció variància entre grups, include=FALSE}
calcBetweenGroupsVariance <- function(variable,groupvariable)
{
  # find out how many values the group variable can take
  groupvariable2 <- as.factor(groupvariable[[1]])
  levels <- levels(groupvariable2)
  numlevels <- length(levels)
  # calculate the overall grand mean:
  grandmean <- mean(as.matrix(variable) )         
  # get the mean and standard deviation for each group:
  numtotal <- 0
  denomtotal <- 0
  for (i in 1:numlevels)
  {
    leveli <- levels[i]
    levelidata <- variable[groupvariable==leveli,]
    levelilength <- length(levelidata)
    # get the mean and standard deviation for group i:
    meani <- mean( as.matrix(levelidata) )
    sdi <- sd(levelidata)
    numi <- levelilength * ((meani - grandmean)^2)
    denomi <- levelilength
    numtotal <- numtotal + numi
    denomtotal <- denomtotal + denomi
  }
  # calculate the between-groups variance
  Vb <- numtotal / (numlevels - 1)
  Vb <- Vb[[1]]
  return(Vb)
}
```

```{r funció que calcula la separació entre grups, include=FALSE}
calcSeparations <- function(variables,groupvariable)
{
  # find out how many variables we have
  variables <- as.data.frame(variables)
  numvariables <- length(variables)
  # find the variable names
  variablenames <- colnames(variables)
  # calculate the separation for each variable
  for (i in 1:numvariables)
  {
    variablei <- variables[i]
    variablename <- variablenames[i]
    Vw <- calcWithinGroupsVariance(variablei, groupvariable)
    Vb <- calcBetweenGroupsVariance(variablei, groupvariable)
    sep <- Vb/Vw
    print(paste("variable", variablename, "Vw =", Vw, "Vb =", Vb, 
                "separation =", sep))
  }
}
```

```{r}
calcSeparations(lda.values$x, data_clas$target)
```

Es dibuixen en un histograma els coeficients de cada funció discriminant. 

```{r, out.width="95%"}
library(tidyverse)
#total separation (la suma de les dues)
#percentatge que separa cada una, coincideix amb la proportion of trace del model discriminant
gg <- data.frame(lda.values$x)
ggplot(gg, aes(x=LD1)) + 
  geom_histogram(color="lightblue", fill="lightblue", binwidth=0.5) + 
  theme_minimal()

ggplot(gg, aes(x=LD2)) + 
  geom_histogram(color="lightblue", fill="lightblue", binwidth=0.5) +
  theme_minimal()
```

Es poden també representar en histogrames els coeficients de la funció discriminant segons el nivell de la variable Target.

LD1

```{r, out.width="88%"}
# histograma múltiple entre la funció discriminant i la resposta (3 histogrames perquè  hi ha 3 modalitats: Graduate, Dropout i Enrolled)
par(mar=c(1,1,1,1))
par(mar=c(5.1,4.1,4.1,2.1))
par(mar=c(3,2.5,1.5,1))
ldahist(data = lda.values$x[,1], g = data_clas$target, ymax = 1)
```

LD2

```{r, out.width="88%"}
ldahist(data = lda.values$x[,2], g = data_clas$target)
```

Es poden també representar les diferents classes de la següent manera: 

```{r}
plot(data_clas$lda1, data_clas$lda2)
text(lda.values$x[, 1], lda.values$x[, 2], data_clas$target, cex = 0.7, pos = 4, 
     col = levels(data_clas$target)) 
```

```{r}
lda$scaling[, 2]
lda$scaling[, 1]
```

```{r}
# predicció de les classes
data_clas$pred = 0
for(i in 1:dim(data_clas)[1]){
  if(data_clas$lda1[i] < 0){data_clas$pred[i] = 2
  }else{if (data_clas$lda2[i]){data_clas$pred[i] = 1 
  }else{
    data_clas$pred[i] = 3
  }
  }
}
```

En tots els gràfics s'aprecia el mateix, no es discriminen bé les modalitats.

Un cop s'han predit les classes de la variable Target, es pot calcular la matriu de confusió per avaluar la precisió de les funcions discriminants que s'han calculat a l'hora de separar les classes. 

```{r}
# matriu de confusió
table(data_clas$target)
MC = table(data_clas$target, data_clas$pred)
```

S'observa, però, que la precisió del model és força baixa, al voltant del 15%.

```{r}
# precisió
(accuracy = sum(diag(MC))/dim(data_clas)[1])
```

Amb la precisió calculada, es pot obtenir l'error de classificació:

```{r}
# error de classificació
(error <- 1 - accuracy)
```
